{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2572 images belonging to 3 classes.\n",
      "Found 400 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 24,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 24,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가\n",
    "import os\n",
    "MODEL_DIR = './model'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                   save_weights_only=True,\n",
    "                                   verbose=1)# Train the model with the new callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.0178 - accuracy: 0.4510\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "108/108 [==============================] - 111s 1s/step - loss: 1.0178 - accuracy: 0.4510 - val_loss: 0.9024 - val_accuracy: 0.6500\n",
      "Epoch 2/3\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.0090 - accuracy: 0.4510\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "108/108 [==============================] - 108s 1s/step - loss: 1.0090 - accuracy: 0.4510 - val_loss: 0.9625 - val_accuracy: 0.6500\n",
      "Epoch 3/3\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.0068 - accuracy: 0.4545\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "108/108 [==============================] - 108s 1000ms/step - loss: 1.0068 - accuracy: 0.4545 - val_loss: 0.9540 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7eb85d5400>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=3,\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\r\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "accuracy: 61.67%\n"
     ]
    }
   ],
   "source": [
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_set, steps=5)\n",
    "\n",
    "#print(his.history['loss'])\n",
    "#print(his.history['acc'])\n",
    "#print(his.history['val_loss'])\n",
    "#print(his.history['val_acc'])\n",
    "\n",
    "#classifier.save(\"face_shape_model.h5\")\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/my_model_02/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/my_model_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_2 (Rescaling)      (None, None, None, None)  0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 32)    896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, None)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 167,621\n",
      "Trainable params: 167,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('models/my_model_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_2 (Rescaling)      (None, None, None, None)  0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 32)    896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, None)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 167,621\n",
      "Trainable params: 167,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조를 확인합니다\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "5/5 [==============================] - 3s 686ms/step - loss: 0.9705 - accuracy: 0.0000e+00\n",
      "복원된 모델의 정확도:  0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9705077409744263"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"-- Evaluate --\")\n",
    "loss, scores = new_model.evaluate(test_set, steps=5)\n",
    "\n",
    "#print(his.history['loss'])\n",
    "#print(his.history['acc'])\n",
    "#print(his.history['val_loss'])\n",
    "#print(his.history['val_acc'])\n",
    "\n",
    "#classifier.save(\"face_shape_model.h5\")\n",
    "print('복원된 모델의 정확도: {:5.2f}%'.format(100*scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('./test_image/ex2.jpg', target_size = (64, 64))\n",
    "#test_image = image.img_to_array(test_image)\n",
    "#test_image = np.expand_dims(test_image, axis = 0)\n",
    "#output = classifier.predict_generator(test_image, steps=5)\n",
    "#output\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "np.around(result)\n",
    "result=result.argmax()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Oblong': 0, 'Round': 1, 'Square': 2}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result == 0:\n",
    "    prediction = 'Oblong'\n",
    "elif result == 1:\n",
    "    prediction = 'Round'\n",
    "else:\n",
    "    prediction = 'Square'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Round'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
